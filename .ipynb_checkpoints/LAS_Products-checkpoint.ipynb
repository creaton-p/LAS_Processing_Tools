{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b17414e7",
   "metadata": {},
   "source": [
    "LAS file Processing Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfba8cb",
   "metadata": {},
   "source": [
    "# Tools for Deriving Products from LAS files\n",
    "## Introduction\n",
    "This jupyter notebook is designed to enable the efficient processing of LAS files. LAS files are an industry standard binary format for storing aerial LiDAR data. The python script in this notebook completes a number of processes useful for analysis. \n",
    "**Note:  As this script uses the arcpy package, it can only be run on a  machine with Arcgis Pro installed although ArcGIS Pro doesn't need to be running.**\n",
    "## Workflow\n",
    "The following processes are carried out in this script.\n",
    "1. A Las dataset is created from the LAS files. A LAS dataset is a file storage container for LAS files used by ESRI\n",
    "2. The ground surface is extracted and classified. This is the process where all the points in the cloud are processed and those deemed to form the bare earth surface are given a classification of \"2\" which is the designation for ground points in the LAS specification.\n",
    "3. A digital Surface Model (DSM) of the pointcloud is generated. This is a raster file with the pixels representing the elevation of the non classified cloud.\n",
    "4. A Digital Terrain Model is created of the ground. This is a raster file with the pixels representing the elevation of the points designated as bare earth.\n",
    "5. A difference raster is created by subtracting the DTM from the DSM to show the vegetation height in the area of interest\n",
    "6. If a shapefile is included containing a line feature class representing cross sections then these will be extracted and plotted in the notebook as well as being exported as a jpeg and a CSV file.\n",
    "\n",
    "** A sample dataset containing a LAS file and a shapefile can be downloaded [here](https://drive.google.com/drive/folders/1oWOcZGH8XyItQWyAD-vEmMEGzo5CKYn_?usp=sharing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc825e3",
   "metadata": {},
   "source": [
    "## Cell 1: Impoting the required modules. \n",
    "Click in the cell below a click run to import the necessary python modules. When it is finished you will see a message saying \"Completed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8451ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a22dc53",
   "metadata": {},
   "source": [
    "## Cell 2: Inputting the variables\n",
    "The cell below requires the user to input the paths and names for various inputs and outputs. If the user is mirroring the same folder naming convention and structure as the default, then no changes are needed. (See the user manual for a full description of the default folder structure). If the user has a different folder structure, then the paths in the variables below need to be altered accordingly.\n",
    "\n",
    "**Note that all but one of the path variables below reference a folder location. For this reason, they are referenced with a double backslash. The user will need to replicate this if copying and pasting a path to their own folder location. The variable \"pointcloud_path\" references the Pointcloud.las file and not the folder containing it so the path to the users own LAS file can be pasted within the quotes. For this reason, the LAS file can have any name.\n",
    "\n",
    "##### arcpy_env_workspace\n",
    "This variable creates a temporary file geodatabase called temp.gdb for storing layers etc while the tool is running. It can be deleted when the session is finished.\n",
    "\n",
    "##### pointcloud_path\n",
    "This is the path to the pointcloud LAS file.\n",
    "\n",
    "##### raster_folder\n",
    "This is the path where the raster output (DTM and DSMs) will be stored\n",
    "\n",
    "##### ground_DSM \n",
    "This is the name of the raster representing the ground surface. The user can use whatever name they choose but the file extension should be .tif format\n",
    "\n",
    "##### surface_model\n",
    "This is the name to be given to the raster representing the DSM. Again the user can choose their own name.\n",
    "\n",
    "##### cross_sections\n",
    "This is the path to the shapefile containing the cross-sections. See the \"Getting Started\" section of theuser manual for the required attributes of the shapefile.\n",
    "\n",
    "The other two variables (**ground_raster_full_path** and **surface_raster_full_path**) are used internally within the code and should not be set by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a017f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "arcpy_env_workspace = \"C:\\\\DSM_Tools\\\\\"  # enter path and name of workspace here\n",
    "pointcloud_path = r\"C:\\DSM_Tools\\LAS_Processing_Tools\\Pointcloud_Data\\Pointcloud.las\" #enter the path to your LAS files\n",
    "las_dataset_path = \"C:\\\\DSM_Tools\\\\LAS_Processing_Tools\\\\Pointcloud_Data\\\\\"# enter las dataset path here\n",
    "raster_folder = \"C:\\\\DSM_Tools\\\\LAS_Processing_Tools\\\\rasters\\\\\"  #enter path to where output rasters ar to be stored\n",
    "ground_dsm = \"ground_DSM.tif\"\n",
    "surface_model = \"surface_DSM.tif\"\n",
    "cross_sections = gpd.read_file(r'C:\\DSM_Tools\\LAS_Processing_Tools\\xsections\\xsections.shp') # enter path to your cross-sections shapefile here\n",
    "surface_raster_full_path = os.path.join(raster_folder, ground_dsm)\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f5811d",
   "metadata": {},
   "source": [
    "## Cell 3\n",
    "This cell creates the temporary file geodatabase in the folder specified in the previous cell. If there is a geodatabase of the same name already there, it will be deleted.This cell needs no input from the user and can be run as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a7220df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\DSM_Tools\\temp.gdb<h2>Messages</h2>Start Time: Saturday, April 24, 2021 9:48:23 AM<br/>Succeeded at Saturday, April 24, 2021 9:48:23 AM (Elapsed Time: 0.04 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\DSM_Tools\\\\temp.gdb'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a temporary geodatabase in workspace\n",
    "if arcpy.Exists(arcpy_env_workspace +\"temp.gdb\"):\n",
    "    arcpy.Delete_management(arcpy_env_workspace +\"temp.gdb\")\n",
    "arcpy.management.CreateFileGDB(arcpy_env_workspace, 'temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d6df9",
   "metadata": {},
   "source": [
    "## Cell 4\n",
    "This cell uses arcpy to create a las dataset which is a pointer to a set of related las files. The parameters that need to be set here are...\n",
    "\n",
    "Input: \"NO_RECURSION\" - only las files in the input folder are added to the dataset or \"RECURSION\" - las files in subdirectories will be added to the dataset.\n",
    "\n",
    "Surface Constraints: Any polygons or other feature classes to be referenced by the LAS dataset. The default is \"None\". See arcgis pro help for more info if feature types are to be included.\n",
    "\n",
    "Coordinate reference system: This is the EPSG code of the CRS for the LAS files. If this is not set then the CRS will be unknown. The default used here is \"27700\" which is the British National Grid.\n",
    "\n",
    "Compute Stats: This is optional and can be set to \"COMPUTE_STATS\" or \"NO_COMPUTE_STATS\"(default). \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd4e945e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-f0281c4dad0c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-f0281c4dad0c>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    if arcpy.Exists(\"las_dataset_path+\"Pointcloud.lasd\"):\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#First make las dataset from pointcloud\n",
    "if arcpy.Exists(las_dataset_path+\"Pointcloud.lasd\"):\n",
    "    arcpy.Delete_management(las_dataset_path+\"Pointcloud.lasd\")\n",
    "\n",
    "\n",
    "\n",
    "arcpy.management.CreateLasDataset(pointcloud_path,\n",
    "                                  las_dataset_path+\"Pointcloud.lasd\", \n",
    "                                  \"NO_RECURSION\", \n",
    "                                  None,\n",
    "                                  arcpy.SpatialReference(27700), \n",
    "                                  \"COMPUTE_STATS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d6079",
   "metadata": {},
   "source": [
    "## Cell 5\n",
    "The code here classifies those points considered to be ground. If the pointcloud has already been classified and has ground points designated in it, then there is no need run the code in this cell. If the cloud hasn't been classified then all the points will have a code of \"1\" (unassigned) or  \"0\" (never classified) \n",
    "The parameters for the user to set here are here are...\n",
    "\n",
    "method: \"STANDARD\", \"CONSRVATIVE\" or \"AGGRESSIVE\". This determines the tollerance for slope variation. \"CONSERVATIVE\" is more likely to filter out sharp changes in slope  that may caused by low lying vegetation such as shrubs where as \"AGGRESSIVE\" detects surfaces with sharper relief. Standard is between the two.\n",
    "\n",
    "Reuse_ground: \"RECLASSIFY_GROUND\" reclassiifes points that have already been classed as ground whereas \"REUSE_GROUND\" accepts point that have already been clasified as ground.\n",
    "\n",
    "compute_stats: see explanation for Cell 4\n",
    "\n",
    "There are other parameters that can be set for this tool such as adding a boundary polygon. The user can review the \"classify las ground tool\" for more information.\n",
    "\n",
    "https://desktop.arcgis.com/en/arcmap/10.5/tools/3d-analyst-toolbox/classify-las-ground.htm\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ff482",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Classify the ground surface\n",
    "\n",
    "arcpy.ddd.ClassifyLasGround(las_dataset_path+\"Pointcloud.lasd\", \n",
    "                            \"AGGRESSIVE\", \n",
    "                            \"RECLASSIFY_GROUND\", \n",
    "                            None, \n",
    "                            \"COMPUTE_STATS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73daeb9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " \n",
    "if arcpy.Exists(\"Pointcloud_LasDatasetLayer\"):\n",
    "    arcpy.Delete_management(\"Pointcloud_LasDatasetLayer\")\n",
    "    \n",
    "\n",
    "arcpy.management.MakeLasDatasetLayer(las_dataset_path+\"Pointcloud.lasd\", \"Pointcloud_LasDatasetLayer\", \"2\", None, \"INCLUDE_UNFLAGGED\", \"INCLUDE_SYNTHETIC\", \"INCLUDE_KEYPOINT\", \"EXCLUDE_WITHHELD\", None, \"INCLUDE_OVERLAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d65df0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if arcpy.Exists(ground_raster_full_path):\n",
    "    arcpy.Delete_management(ground_raster_full_path)\n",
    "arcpy.conversion.LasDatasetToRaster(\"Pointcloud_LasDatasetLayer\", ground_raster_full_path, \"ELEVATION\", \"BINNING AVERAGE LINEAR\", \"FLOAT\", \"CELLSIZE\", 0.1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in cross_sections.iterrows():\n",
    "     XS_id = row['xs_id'] # input shapefile id colunm name here\n",
    "\n",
    " ##This section of code shows how to create a x-section from a shapefile\n",
    "     start_coords = list([row.geometry][0].coords)[0]\n",
    "     end_coords = list([row.geometry][0].coords)[1]\n",
    "     eastings = [start_coords[0]] #eastings of start point\n",
    "     northings = [start_coords[1]] #northings of start point written as a list so it has an append attribute\n",
    "     no_pts = 100 # this is the number of points the dsm will be sampled at between the two end points of each x-section\n",
    "\n",
    "\n",
    "     # np.arange subdivides a line equally between two points.\n",
    "     for i in np.arange(1, no_pts+1):  # we have no_points + 1 as np.arrange doesnt include the last point\n",
    "         x_dist = end_coords[0]-start_coords[0]  #difference between eastings\n",
    "         y_dist = end_coords[1]-start_coords[1]  # difference between northings\n",
    "         point = [(start_coords[0] + (x_dist/(no_pts+1))*i), (start_coords[1] + (y_dist/(no_pts+1))*i)]\n",
    "         eastings.append(point[0])\n",
    "         northings.append(point[1])\n",
    "\n",
    "     eastings.append(end_coords[0])\n",
    "     northings.append(end_coords[1]) #the end coordinates are now appended to the coordinate list\n",
    "\n",
    "     # Make points from x-section list and into a pandas dataframe\n",
    "     dfr = pd.DataFrame({'Eastings': eastings,\n",
    "                           'Northings': northings})\n",
    "\n",
    "     #make a geodataframe from pandas df\n",
    "     gdfr = gpd.GeoDataFrame(dfr, geometry = gpd.points_from_xy(dfr['Eastings'], dfr['Northings']), crs= 'EPSG:27700')\n",
    "\n",
    "     #add a horizontal distance from beginning of line for x-section plot\n",
    "     gdfr['hz_dist'] = 0\n",
    "\n",
    "     for index, row in gdfr.iterrows():\n",
    "         gdfr['hz_dist'].loc[index]  = gdfr.geometry[0].distance(gdfr.geometry[index])\n",
    "\n",
    "\n",
    "\n",
    "     #Extracting elevations from DEM\n",
    "     # First create 'Elevation' column in gdfr and assign initial value of 0\n",
    "     gdfr['Elevation'] =0\n",
    "\n",
    "\n",
    "     ##dsm = rasterio.open(r'C:\\Tool\\DSM_Processing\\Pointcloud_Data\\Pointcloud.tif', mode = 'r') # enter path to raster here\n",
    "     dsm = rasterio.open(r\"C:\\Tool\\DSM_Processing\\rasters\\ground_DSM.tif\", mode='r')  # enter path to raster here\n",
    "\n",
    "     for index, row in gdfr.iterrows():  # this looks through each row on the index column and extracts the N & E\n",
    "         row, col = dsm.index(row['Eastings'], row['Northings'])\n",
    "         dsm_data =dsm.read(1)\n",
    "\n",
    "         gdfr['Elevation'].loc[index] = dsm_data[row, col]  # this creates a column called Elevation in the x-section and assigns the raster elevation to it.\n",
    "\n",
    "  # Extract hz_dist (x) and Elevation (y) into Pandas df\n",
    "     x_y_data = gdfr[['hz_dist', 'Elevation']]\n",
    "     x_y_data.to_csv(r'C:\\Tool\\DSM_Processing\\extracted_sections' + '\\\\' + XS_id + '.csv')\n",
    "\n",
    "     # Create plots using matplotlib for each x-section\n",
    "     plt.plot(gdfr['hz_dist'], gdfr['Elevation'])\n",
    "     plt.xlabel('Distance (m)')\n",
    "     plt.ylabel('Elevation (m)')\n",
    "     plt.grid(True)\n",
    "     plt.title(XS_id)\n",
    "     plt.savefig(r'C:\\Tool\\DSM_Processing\\extracted_sections'+ '\\\\'+ XS_id + '.jpg')\n",
    "     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print (\"Script Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
