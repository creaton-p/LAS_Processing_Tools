{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e62969",
   "metadata": {},
   "source": [
    "LAS file Processing Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9caa6",
   "metadata": {},
   "source": [
    "# Tools for Deriving Products from LAS files\n",
    "## Introduction\n",
    "This jupyter notebook is designed to enable the efficient processing of LAS files. LAS files are an industry standard binary format for storing aerial LiDAR data. The python script in this notebook completes a number of processes useful for analysis. \n",
    "**Note:  As this script uses the arcpy package, it can only be run on a  machine with Arcgis Pro installed although ArcGIS Pro doesn't need to be running.**\n",
    "## Workflow\n",
    "The following processes are carried out in this script.\n",
    "1. A Las dataset is created from the LAS files. A LAS dataset is a file storage container for LAS files used by ESRI.\n",
    "2. The ground surface is extracted and classified. This is the process where all the points in the cloud are processed and those deemed to form the bare earth surface are given a classification of \"2\" which is the designation for ground points in the LAS specification.\n",
    "3. A digital Surface Model (DSM) of the pointcloud is generated. This is a raster file with the pixels representing the elevation of the non classified cloud.\n",
    "4. A Digital Terrain Model is created of the ground. This is a raster file with the pixels representing the elevation of the points designated as bare earth.\n",
    "5. A difference raster is created by subtracting the DTM from the DSM to show the vegetation height in the area of interest.\n",
    "6. If a shapefile is included containing a line feature class representing cross sections then these will be extracted and plotted in the notebook as well as being exported as a jpeg and a CSV file.\n",
    "\n",
    "** A sample dataset containing a LAS file and the required shapefiles(cross-section and a polygon region of interest) can be downloaded [here](https://drive.google.com/drive/folders/1oWOcZGH8XyItQWyAD-vEmMEGzo5CKYn_?usp=sharing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe54046c",
   "metadata": {},
   "source": [
    "## Cell 1: Impoting the required modules. \n",
    "Click in the cell below a click run to import the necessary python modules. When it is finished you will see a message saying \"Completed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da658cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import cartopy.crs as ccrs\n",
    "import os\n",
    "\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dd7e8c",
   "metadata": {},
   "source": [
    "## Cell 2: Inputting the variables\n",
    "The cell below requires the user to input the paths and names for various inputs and outputs. If the user is mirroring the same folder naming convention and structure as the default (recommended), then no changes are needed. (See the user manual for a full description of the default folder structure). If the user has a different folder structure, then the paths in the variables below need to be altered accordingly.\n",
    "\n",
    "**Note that all but one of the path variables below reference a folder location. For this reason, they are referenced with a double backslash. The user will need to replicate this if copying and pasting a path to their own folder location. The variable \"pointcloud_path\" references the Pointcloud.las file and not the folder containing it so the path to the users own LAS file can be pasted within the quotes. For this reason, the LAS file can have any name.\n",
    "\n",
    "##### arcpy_env_workspace\n",
    "This variable creates a temporary file geodatabase called temp.gdb for storing layers etc while the tool is running. It can be deleted when the session is finished.\n",
    "\n",
    "##### pointcloud_path\n",
    "This is the path to the pointcloud LAS file.\n",
    "\n",
    "##### raster_folder\n",
    "This is the path where the raster output (DTM and DSMs) will be stored\n",
    "\n",
    "##### ground_DSM \n",
    "This is the name of the raster representing the ground surface. The user can use whatever name they choose but the file extension should be .tif format\n",
    "\n",
    "##### surface_model\n",
    "This is the name to be given to the raster representing the DSM. Again the user can choose their own name.\n",
    "\n",
    "##### cross_sections\n",
    "This is the path to the shapefile containing the cross-sections. See the \"Getting Started\" section of the user manual for the required attributes of the shapefile.\n",
    "\n",
    "##### clip_region\n",
    "This is a polygon shapefile to be used to clip the las data and the resultin rasters to the same extents. This is highly recommended as it can be difficult performing raster calculations if the rasters have different boundaries.\n",
    "\n",
    "The other two variables (**ground_raster_full_path** and **surface_raster_full_path**) are used internally within the code and should not be set by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2cb5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy_env_workspace = \"C:\\\\DSM_Tools\\\\\"  # enter path and name of workspace here\n",
    "pointcloud_path = r\"C:\\DSM_Tools\\LAS_Processing_Tools\\Pointcloud_Data\\Pointcloud.las\" #enter the path to your LAS files\n",
    "las_dataset_path = \"C:\\\\DSM_Tools\\\\LAS_Processing_Tools\\\\Pointcloud_Data\\\\\"# enter las dataset path here\n",
    "raster_folder = \"C:\\\\DSM_Tools\\\\LAS_Processing_Tools\\\\rasters\\\\\"  #enter path to where output rasters ar to be stored\n",
    "ground_dsm = \"ground_DSM.tif\"\n",
    "surface_model = \"surface_DSM.tif\"\n",
    "cross_sections = gpd.read_file(r'C:\\DSM_Tools\\LAS_Processing_Tools\\xsections\\xsections.shp') # enter path to your cross-sections shapefile here\n",
    "clip_region = r\"C:\\DSM_Tools\\LAS_Processing_Tools\\clip_region\\clip_region.shp\"\n",
    "ground_raster_full_path = os.path.join(raster_folder, ground_dsm)\n",
    "surface_model_full_path = os.path.join(raster_folder, surface_model)\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f4053b",
   "metadata": {},
   "source": [
    "## Cell 3\n",
    "This cell creates the temporary file geodatabase in the folder specified in the previous cell. If there is a geodatabase of the same name already there, it will be deleted.This cell needs no input from the user and can be run as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57fe823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a temporary geodatabase in workspace\n",
    "if arcpy.Exists(arcpy_env_workspace +\"temp.gdb\"):\n",
    "    arcpy.Delete_management(arcpy_env_workspace +\"temp.gdb\")\n",
    "arcpy.management.CreateFileGDB(arcpy_env_workspace, 'temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75413dbd",
   "metadata": {},
   "source": [
    "## Cell 4\n",
    "This cell uses arcpy to create a las dataset which is a pointer to a set of related las files. The parameters that need to be set here are...\n",
    "\n",
    "Input: \"NO_RECURSION\" - only las files in the input folder are added to the dataset or \"RECURSION\" - las files in subdirectories will be added to the dataset.\n",
    "\n",
    "Surface Constraints: Any polygons or other feature classes to be referenced by the LAS dataset. Here we have used the “clip_region” shapefile.\n",
    "\n",
    "Coordinate reference system: This is the EPSG code of the CRS for the LAS files. If this is not set then the CRS will be unknown. The default used here is \"27700\" which is the British National Grid.\n",
    "\n",
    "Compute Stats: This is optional and can be set to \"COMPUTE_STATS\" or \"NO_COMPUTE_STATS\"(default). \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9de950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#First make las dataset from pointcloud\n",
    "if arcpy.Exists(las_dataset_path+\"Pointcloud.lasd\"):\n",
    "    arcpy.Delete_management(las_dataset_path+\"Pointcloud.lasd\")\n",
    "\n",
    "arcpy.management.CreateLasDataset(pointcloud_path,\n",
    "                                  las_dataset_path+\"Pointcloud.lasd\", \n",
    "                                  \"NO_RECURSION\",\n",
    "                                  clip_region,\n",
    "                                  arcpy.SpatialReference(27700), \n",
    "                                  \"COMPUTE_STATS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c417d3",
   "metadata": {},
   "source": [
    "## Cell 5\n",
    "The code here classifies those points considered to be ground. If the pointcloud has already been classified and has ground points designated in it, then there is no need run the code in this cell. If the cloud has not  been classified then all the points will have a code of \"1\" (unassigned) or  \"0\" (never classified).  \n",
    "The parameters for the user to set here are here are...\n",
    "\n",
    "method: \"STANDARD\", \"CONSRVATIVE\" or \"AGGRESSIVE\". This determines the tollerance for slope variation. \"CONSERVATIVE\" is more likely to filter out sharp changes in slope  that may caused by low lying vegetation such as shrubs where as \"AGGRESSIVE\" detects surfaces with sharper relief. Standard is between the two.\n",
    "\n",
    "Reuse_ground: \"RECLASSIFY_GROUND\" reclassiifes points that have already been classed as ground whereas \"REUSE_GROUND\" accepts point that have already been clasified as ground.\n",
    "\n",
    "compute_stats: see explanation for Cell 4\n",
    "\n",
    "The “None” value in the code indicates that no DSM resolution has been included. This parameter can be set to filter the number of points  being evaluated to save processing time. \n",
    "\n",
    "There are other parameters that can be set for this tool such as adding a boundary polygon. The user can review the \"classify las ground tool\" for more information.\n",
    "\n",
    "https://desktop.arcgis.com/en/arcmap/10.5/tools/3d-analyst-toolbox/classify-las-ground.htm\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c7c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Classify the ground surface\n",
    "\n",
    "arcpy.ddd.ClassifyLasGround(las_dataset_path+\"Pointcloud.lasd\", \n",
    "                            \"AGGRESSIVE\", \n",
    "                            \"RECLASSIFY_GROUND\",\n",
    "                            None, \n",
    "                            \"COMPUTE_STATS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3732b2",
   "metadata": {},
   "source": [
    "# Cell 6\n",
    "The code here creates a temporary layer of the ground points only. From this the DTM will be created. The parameter \"2\" in the code refers to the las code of the ground surface. If this layer exists it will first be deleted. This cell needs no input from the user and can be run as it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c29bdb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " \n",
    "if arcpy.Exists(\"Pointcloud_LasDatasetLayer\"):\n",
    "    arcpy.Delete_management(\"Pointcloud_LasDatasetLayer\")\n",
    "    \n",
    "\n",
    "arcpy.management.MakeLasDatasetLayer(las_dataset_path+\"Pointcloud.lasd\", \"Pointcloud_LasDatasetLayer\", \"2\", None, \"INCLUDE_UNFLAGGED\", \"INCLUDE_SYNTHETIC\", \"INCLUDE_KEYPOINT\", \"EXCLUDE_WITHHELD\", None, \"INCLUDE_OVERLAP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b68c0",
   "metadata": {},
   "source": [
    "# Cell 7\n",
    "This cell is the first of two that create the rasters from the LiDAR. Again, if the raster already exists it will first be deleted before the new one is generated. This first cell creates a raster layer from the ground points only. The user can review the \"Las Dataset to Raster Tool\" for more information. The parameters that have been set here are...\n",
    "\n",
    "value_field: This states that the value to be used for the pixel value is the \"ELEVATION\". It is important to specify this as LiDAR data can also come with an \"INTENSITY\" field and an \"RGB\" field.\n",
    "\n",
    "interpolation_type: Here it is set to \"BINNING AVERAGE LINEAR\" which means each cell will take the average of the z values within it and that there will be a linear interpolation across cells that don't have any points in them.\n",
    "\n",
    "data_type: This is set to \"FLOAT\" which means it will be a 32-bit floating point data type.\n",
    "\n",
    "sampling_type: Set to \"CELLSIZE\" which defines the length of the sides of each raster cell on the ground.\n",
    "\n",
    "\n",
    "\n",
    "https://pro.arcgis.com/en/pro-app/latest/tool-reference/conversion/las-dataset-to-raster.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fcf5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if arcpy.Exists(ground_raster_full_path):\n",
    "    arcpy.Delete_management(ground_raster_full_path)\n",
    "arcpy.conversion.LasDatasetToRaster(\"Pointcloud_LasDatasetLayer\", ground_raster_full_path, \n",
    "                                    \"ELEVATION\", \"BINNING AVERAGE LINEAR\", \"FLOAT\", \"CELLSIZE\", 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803a64d8",
   "metadata": {},
   "source": [
    "# Cell 8\n",
    "This cell creates the second raster with the parameters matching those in Cell 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907f93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arcpy.Exists(surface_model_full_path):\n",
    "    arcpy.Delete_management(surface_model_full_path)\n",
    "                \n",
    "                \n",
    "arcpy.conversion.LasDatasetToRaster(las_dataset_path+\"Pointcloud.lasd\", surface_model_full_path, \n",
    "                                    \"ELEVATION\", \"BINNING AVERAGE LINEAR\", \"FLOAT\", \"CELLSIZE\", 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf0af4",
   "metadata": {},
   "source": [
    "# Cells 9 & 10\n",
    "The code in the cells below creates the cross-sections from the 'xsections.shp' file. It is based on the tutorials given by Geo Delta Labs. This will sample the DTM at a number of equally spaced points specified by the user in the cell below. The default is 20. \n",
    "\n",
    "The ground_DSM will be sampled at these points as well as at the beginning and end of the line. The user is only required to enter the number of points in the cell below and define which surface model they wish to have the cells extracted from using the path variables defined in Cell 2.\n",
    "\n",
    "When the code is run a plot of each section is created in the cell below. The code also exports a jpg and a csv of each section to the \"Extracted_sections\" folder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee724fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ofPoints = 20  # enter the number of sample points for sampling between the two end points.\n",
    "surface_choice = ground_raster_full_path  # If sections are to be extracted on the surface model use \"surface_model_full_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499a8a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapefile id colunm name added here\n",
    "for index, row in cross_sections.iterrows():\n",
    "     XS_id = row['xs_id'] \n",
    "\n",
    "##This section of code shows how to create a x-section from a shapefile\n",
    "     start_coords = list([row.geometry][0].coords)[0]\n",
    "     end_coords = list([row.geometry][0].coords)[1]\n",
    "     eastings = [start_coords[0]] #eastings of start point\n",
    "     northings = [start_coords[1]] #northings of start point written as a list so it has an append attribute\n",
    "     no_pts = no_ofPoints # this is the number of points the dsm will be sampled at between the two end points of each x-section\n",
    "\n",
    "\n",
    "     # np.arange subdivides a line equally between two points.\n",
    "     for i in np.arange(1, no_pts+1):  # we have no_points + 1 as np.arrange doesnt include the last point\n",
    "         x_dist = end_coords[0]-start_coords[0]  #difference between eastings\n",
    "         y_dist = end_coords[1]-start_coords[1]  # difference between northings\n",
    "         point = [(start_coords[0] + (x_dist/(no_pts+1))*i), (start_coords[1] + (y_dist/(no_pts+1))*i)]\n",
    "         eastings.append(point[0])\n",
    "         northings.append(point[1])\n",
    "\n",
    "     eastings.append(end_coords[0])\n",
    "     northings.append(end_coords[1]) #the end coordinates are now appended to the coordinate list\n",
    "\n",
    "     # Make points from x-section list and into a pandas dataframe\n",
    "     dfr = pd.DataFrame({'Eastings': eastings,\n",
    "                           'Northings': northings})\n",
    "\n",
    "     #make a geodataframe from pandas df\n",
    "     gdfr = gpd.GeoDataFrame(dfr, geometry = gpd.points_from_xy(dfr['Eastings'], dfr['Northings']), crs= 'EPSG:27700')\n",
    "\n",
    "     #add a horizontal distance from beginning of line for x-section plot\n",
    "     gdfr['hz_dist'] = 0\n",
    "\n",
    "     for index, row in gdfr.iterrows():\n",
    "         gdfr['hz_dist'].loc[index]  = gdfr.geometry[0].distance(gdfr.geometry[index])\n",
    "\n",
    "\n",
    "\n",
    "     #Extracting elevations from DEM\n",
    "     # First create 'Elevation' column in gdfr and assign initial value of 0\n",
    "     gdfr['Elevation'] =0\n",
    "\n",
    "\n",
    "#      ## raster path is entered \n",
    "     dsm =  rasterio.open(surface_choice, mode='r')  # enter path to raster here\n",
    "\n",
    "     for index, row in gdfr.iterrows():  # this looks through each row on the index column and extracts the N & E\n",
    "         row, col = dsm.index(row['Eastings'], row['Northings'])\n",
    "         dsm_data =dsm.read(1)\n",
    "\n",
    "         gdfr['Elevation'].loc[index] = dsm_data[row, col]  # this creates a column called Elevation in the x-section and assigns the raster elevation to it.\n",
    "\n",
    "  # Extract hz_dist (x) and Elevation (y) into Pandas df\n",
    "     x_y_data = gdfr[['hz_dist', 'Elevation']]\n",
    "     x_y_data.to_csv(r'C:\\DSM_Tools\\LAS_Processing_Tools\\Extracted_sections' + '\\\\' + XS_id + '.csv')\n",
    "\n",
    "    ## Create plots using matplotlib for each x-section\n",
    "     plt.plot(gdfr['hz_dist'], gdfr['Elevation'])\n",
    "     plt.xlabel('Distance (m)')\n",
    "     plt.ylabel('Elevation (m)')\n",
    "     plt.grid(True)\n",
    "     plt.title(XS_id)\n",
    "    ##Save csv and jpg images in \"Extracted_sections\" folder\n",
    "     plt.savefig(r'C:\\DSM_Tools\\LAS_Processing_Tools\\Extracted_sections'+ '\\\\'+ XS_id + '.jpg')\n",
    "     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print (\"Script Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4b0a8",
   "metadata": {},
   "source": [
    "# Cell 11\n",
    "This cell uses rasterio to open and read the two surface models and subtracts the ground model from the surface model. This creates a canopy height model. No user input is needed for this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6955c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grnd_DTM = rasterio.open(ground_raster_full_path)\n",
    "ground_array = grnd_DTM.read(1, masked = True)\n",
    "sfc_DTM = rasterio.open(surface_model_full_path)\n",
    "surface_array= sfc_DTM.read(1, masked = True)\n",
    "canopy_ht = surface_array-ground_array\n",
    "min_val =canopy_ht.min()\n",
    "max_val=canopy_ht.max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e403a82f",
   "metadata": {},
   "source": [
    "# Cell 12\n",
    "The cell below creates a canopy height raster and saves it as a .tif file in the rasters folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(ground_raster_full_path) as src:\n",
    "    profile = src.profile\n",
    "    band_number = 1\n",
    "# to update the dtype\n",
    "    profile.update(dtype=canopy_ht.dtype)\n",
    "\n",
    "with rasterio.open(raster_folder+'canopy_ht.tif', 'w', **profile) as dst:\n",
    "    dst.write(canopy_ht, band_number)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9926a716",
   "metadata": {},
   "source": [
    "# Cell 13\n",
    "This last cell creates a plot of the canopy height model in the jupyter notebook using the Matplotlib package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5456599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(raster_folder+'canopy_ht.tif') as dataset:\n",
    "    img = dataset.read(1, masked = True)\n",
    "    fig, ax = plt.subplots(1, figsize=(10,10))\n",
    "    pos = ax.imshow(img, cmap='hsv', vmin=min_val, vmax=max_val)\n",
    "    fig.colorbar(pos, ax=ax)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7f919d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
